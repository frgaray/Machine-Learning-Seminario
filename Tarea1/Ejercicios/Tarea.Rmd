---
title: "Tarea 1"
output: pdf_document
---
## Ejercicio 4
```{r, include=F}
data <- read.csv("Datos/Preg4.csv")
data$logPop <- log(data$Pop)
```

Analicemos los datos.

```{r, echo=F}
library(ggplot2)
ggplot(data=data,
       aes(x=Age, y=Cases/Pop, colour=City)) +
  geom_point() +
  theme_classic()
```

Podemos observar una fuerte tendencia en los datos respecto a la tasa de incidencia
de los casos de cáncer de pulmón contra la edad, hay un claro incremento conforme
avanzamos en los grupos de edad.

También podríamos argumentar que la distinción por ciudades no hace un gran cambio
a simple vista. Probablemente la inclusión de esta variable cause ruido en nuestro
modelo, pero no podemos descartar que afecte la ciudad para la tasa hasta hacer una
prueba formal.

### Modelos con Poisson

Para descartar este hecho, hemos hecho dos modelos y los contrastamos. En el primero
consideraremos todas las interacciones entre la edad y la ciudad, y en el segundo
únicamente a los grupos de edad.

En ambos casos los modelos fueron basados en la distribución Poisson con liga logarítmica.

```{r, include=F}
fit.poi1 <- glm(Cases ~ Age*City + offset(logPop),
               family = poisson(link='log'),
               data = data)
fit.poi2 <- glm(Cases ~ Age + offset(logPop),
                family = poisson(link='log'),
                data = data)
summary(fit.poi1)
summary(fit.poi2)
```

Nuestro primer modelo con todas las interacciones entre ciudad y grupos de edad
no cumple siquiera con los supuestos, mientras que el segundo únicamente considerando
los grupos de edad sí los cumple.

```{r, include=F}
library(DHARMa)  
set.seed(1)
fit.poi1.res <- simulateResiduals(fit.poi1)
plot(fit.poi1.res)
fit.poi2.res <- simulateResiduals(fit.poi2)
plot(fit.poi2.res)
```

Además de esto, el primer modelo generó una barbaridad de coeficientes. Deseamos poder
considerar al segundo modelo en su lugar. En este caso usamos criterios como el AIC,
BIC y una prueba de bondad de ajuste ya que estos modelos están anidados y queremos
tomar al segundo modelo, que es una versión reducida del primero.

Primero los AIC y BIC:

```{r}
c(AIC(fit.poi1), AIC(fit.poi2))
c(BIC(fit.poi1), BIC(fit.poi2))
```

Tenemos menores AIC y BIC para el segundo modelo.

Ahora la prueba de bondad de ajuste:

```{r, echo=F}
anova(fit.poi1, fit.poi2, test = 'Chisq')
```

Como obtuvimos un p-value de 0.32, no tenemos evidencia en contra de que debemos
tomar el modelo completo ante el reducido. Es decir, podemos quedarnos con el reducido.

Y esto hace mucho sentido ya que desde un inicio, en la gráfica pudimos observar
que independientemente de la ciudad, las tasas de incidencia parecían ser muy iguales
entre todas.


### Modelo Binomial Negativo

Ahora que hemos seleccionado un buen modelo Poisson con liga logarítmica, también probaremos
un ajuste con la distribución Binomial Negativa (liga logarítmica de igual manera).

```{r, include=F}
library(MASS)
fit.nb <- glm.nb(Cases ~ Age + offset(logPop),
                 link = 'log',
                 data = data)
```

Este nuevo modelo con la distribución Binomial Negativa también cumple con los
supuestos.

```{r, include=F}
set.seed(1)
fit.nb.res <- simulateResiduals(fit.nb)
plot(fit.nb.res)
```

Por lo que podemos comparar los AIC y BIC de este modelo con el Poisson anterior
y decidirnos por alguno:

```{r}
c(AIC(fit.nb), AIC(fit.poi2))
c(BIC(fit.nb), BIC(fit.poi2))
```

El modelo Poisson tiene menores índices, por lo que también lo seleccionamos por
encima del binomial negativo.

### Intervalos de Confianza: Grupos de Edad

Mostraremos intervalos de confianza al 95% para los diferentes grupos de edades:

```{r, echo=F}
library(multcomp)
K=matrix(c(1, 0, 0, 0, 0,
           1, 1, 0, 0, 0,
           1, 0, 1, 0, 0,
           1, 0, 0, 1, 0,
           1, 0, 0, 0, 1), ncol=5, nrow=5, byrow=TRUE)
fitE <- glht(fit.poi2, linfct = K)
fitci <- confint(fitE, level = 0.95)

confint <- exp(fitci$confint)
ci.lwr <- confint[,2]
ci.upr <- confint[,3]

ggplot(data=data,
       aes(x=Age, y=Cases/Pop, colour=City)) +
  geom_point() +
  geom_segment(aes(x=1, y=ci.lwr[1], xend=1, yend=ci.upr[1]), linetype=2, color='black') +
  geom_segment(aes(x=2, y=ci.lwr[2], xend=2, yend=ci.upr[2]), linetype=2, color='black') +
  geom_segment(aes(x=3, y=ci.lwr[3], xend=3, yend=ci.upr[3]), linetype=2, color='black') +
  geom_segment(aes(x=4, y=ci.lwr[4], xend=4, yend=ci.upr[4]), linetype=2, color='black') +
  geom_segment(aes(x=5, y=ci.lwr[5], xend=5, yend=ci.upr[5]), linetype=2, color='black') +
  theme_classic()
```

A ojo gracias a estos intervalos de confianza podemos suponer que en efecto, a mayor
edad mayores tasas de incidencias. Pero haremos una prueba para verificar esto.

Contrastamos los dos primeros grupos de edad, 40-54 y 55-59, contra los dos últimos,
65-69 y 70-74, ya que a ojo es evidente que a gran escala sí podemos concluir
que hay un aumento en la tasa de incidencia de casos de cáncer de pulmón.

Serán pruebas simultáneas siguiendo la lógica

$H_0:\mu(Cases/Pop\ |\ AgeGroup_{70-74}) \leq \mu(Cases/Pop\ |\ AgeGroup_{40-54})$

Y más estrictamente contrastamos la siguiente hipótesis:

$H_0:\beta_4 - \beta_0 \leq 0\ \cap\ \beta_3 - \beta_0 \leq 0\ \cap\ \beta_4 - \beta_1 \leq 0\ \cap \beta_3 - \beta_1 \leq 0$

Es decir, las pruebas del primer grupo contra los últimos dos grupos de edad, y
del segundo grupo contra los dos últimos grupos de edad.

```{r, echo=F}
K=matrix(c(-1,  0, 0, 0, 1,
           -1,  0, 0, 1, 0,
            0, -1, 0, 0, 1,
            0, -1, 0, 1, 0), ncol=5, nrow=4, byrow=T)
m=c(0,0,0,0)
summary(glht(fit.poi2, linfct = K, rhs=m, alternative='greater'))
```

En todas las pruebas obtuvimos un p-value menor al 0.05, por lo que en efecto
tenemos evidencia en contra de que al aumentar la edad se reduce el riesgo.

Es decir, que lo que suponíamos se cumple. A mayor edad mayor riesgo de padecer
cáncer de pulmón.

### Modelo con Edad Continua

Por último consideramos un modelo suponiendo que la edad es una variable continua,
no categórica. Para eso les dimos una edad puntual a cada observación de cada grupo.
Ésta fue el punto medio de su grupo de edad (por ejemplo al Grupo 40-54 se le asignó
la edad de 47 años)

```{r, include=F}
data1 <- data
data1$Ageprima <- data1$X
data1[data1$Age=="40-54",]$Ageprima <- (54+40)/2
data1[data1$Age=="55-59",]$Ageprima <- (55+59)/2
data1[data1$Age=="60-64",]$Ageprima <- (60+64)/2
data1[data1$Age=="65-69",]$Ageprima <- (65+69)/2
data1[data1$Age=="70-74",]$Ageprima <- (70+74)/2
```

Creamos 4 modelos, 2 con Poisson y liga logarítmica y 2 con Binomial Negativa y la 
misma función liga. Para cada distribución consideramos un modelo con sólo interacciones
de la edad vista como variable continua, y para su segundo modelo respectivo uno donde
se tome en cuenta la edad y la edad^2 como variables continuas.

```{r, include=F}
fit1 <- glm(Cases ~ Ageprima + offset(logPop),
               family = poisson(link='log'),
               data = data1)
fit2 <- glm(Cases ~ Ageprima + I(Ageprima^2) + offset(logPop),
               family = poisson(link='log'),
               data = data1)
fit3 <- glm.nb(Cases ~ Ageprima + offset(logPop),
                 link = 'log',
                 data = data1)
fit4 <- glm.nb(Cases ~ Ageprima + I(Ageprima^2) + offset(logPop),
                 link = 'log',
                 data = data1)

set.seed(1)
fit1.res <- simulateResiduals(fit1)
plot(fit1.res)
fit2.res <- simulateResiduals(fit2)
plot(fit2.res)
fit3.res <- simulateResiduals(fit3)
plot(fit3.res)
fit4.res <- simulateResiduals(fit4)
plot(fit4.res)

Poi <- fit2
BN <- fit4
```

Desafortunadamente sólo 2 de los 4 modelos cumplen con los supuestos, y coinciden
en ser los dos modelos donde se toma en cuenta la influencia de la edad y la edad^2
(es decir tenemos un modelo Poisson y uno Binomial Negativo).

A continuación mostramos sus AIC y BIC:

```{r}
c(AIC(Poi), AIC(BN))
c(BIC(Poi), BIC(BN))
```

Por lo que consideraremos el Poisson.

Para finalizar este reporte, mostraremos intervalos de confianza continuos usando
este último modelo tomando a la edad como variable continua para
apoyar el hecho de que a mayor edad, mayor incidencia de cáncer de pulmón.

```{r, echo=F}
age <- seq(from = 40, to = 74, by = .5)
K <- cbind(1, age, age^2)
fitE <- glht(fit2, linfct = K)
fitci <- confint(fitE, level = 0.95)

plot(x = data1$Ageprima, y = data1$Cases/data1$Pop)
lines(age, exp(coef(fitE)[1:69]), col="red")
lines(age, exp(fitci$confint[1:69,"upr"]), col="red", lty=2)
lines(age, exp(fitci$confint[1:69,"lwr"]), col="red", lty=2)
```


Para dar un poco más de rigurisidad veamos que esto tiene sentido, ya que nuestra
variable edad sólo nos interesa en valores entre 40 y 74 años, es decir
$40 \leq x \leq 74$, donde x representa la edad de algún paciente. Y si a mayor
edad, mayor probabilidad de tener cáncer, eso nos implicaría que nuestra
función de incidencia es creciente respecto a la edad. Lo que a su vez lo podemos
traducir en que si tenemos una derivada positiva de esta función para el intervalo
$[40,\ 74]$, entonces en efecto podemos concluir lo deseado. 

Esto se cumple ya que, equivalentemente, la derivada de nuestra función liga se ve así:

$\frac{d}{dx}\mu(Cases/Pop\ |\ Age = x) = \frac{d}{dx}(\beta_0 + \beta_1x + \beta_2x^2)$
$= \beta_1 + 2\beta_2x$, y dado a que nuestros valores del modelo de $\beta_1$ y $\beta_2$
son respectivamente 0.3723 y -0.0025, la recta $\beta_1 + 2\beta_2x$ es positiva
en el intervalo $(-\infty, \frac{-\beta_1}{2\beta_2}) = (-\infty, 74.46)$.

En particular la derivada $\frac{d}{dx}\mu(Cases/Pop\ |\ Age = x) = \beta_1 + 2\beta_2x$
es positiva en el intervalo $[40,\ 74]$.

Con lo que concluimos que en efecto a mayor edad, mayor indicencia en los casos
de cáncer de pulmón, pues la función de tasa de incidencia es creciente en el
intervalo deseado.







## Ejercicio 5

Presentaremos la gráfica de los datos, donde la notación usada por simplicidad es
la siguiente.

Para el tipo de viviendas: Tower=To, Atrium=At, Apartment=Ap, Terrace=Te

Para los niveles ordinales: Low=L, Medium=M, High=H

Además los datos son presentados en el formato "Vivienda.Influencia.Contacto".
Por ejemplo la etiqueta To.M.L nos indica que hablamos de los inquilinos con vivienda
tipo Tower, que perciben su influencia del mantenimiento de la vivienda como Medium,
y que su contacto con el resto de inquilinos es Low.

```{r, echo=F}
data <- read.csv("Datos/Preg5.csv")

#i)
library(lessR)
data$Type.Infl.Cont <- factor(paste(substr(data$Type, 1, 2),           #Tower=To, Atrium=At, ...
                                    substr(data$Infl, 1, 1),           #High=H, Medium=M, Low=L
                                    substr(data$Cont, 1, 1),           #High=H, Low=L
                                    sep= '.'))
Satisfaction <- data$Sat
Type.Infl.Cont <- data$Type.Infl.Cont
BarChart(Type.Infl.Cont, by=Satisfaction, stack100=T, horiz=T)
```

En general no podemos observar grandes patrones, salvo unos pocos.

Por ejemplo, aquellos inquilinos que se consideran con influencia en el mantenimiento
como High y a su vez tienen buena comunicación con los demás, su nivel de satisfacción
siempre es mayor al 50%, esto hace sentido ya que sentir que su opinión importa
y tener buena comunicación con los demás puede influir en sentirse cómodos en su vivienda.

Por otro lado, cuando se consideran con influencia Low y comunicación Low, salvo por
los inquilinos que viven en Tower, tienen un índice del 40% en sentirse poco satisfechos.

Otro dato a notar, es que en general los individuos que viven en Tower tienden a ser
los que se sienten más satisfechos, seguidos por los que viven en Apartment.

```{r}
#ii)
library(VGAM)

data$Sat <- factor(data$Sat, levels=c('Low', 'Medium', 'High'))
data$Infl <- factor(data$Infl, levels=c('Low', 'Medium', 'High'))
data$Type <- factor(data$Type, levels=c('Tower', 'Apartment', 'Atrium', 'Terrace'))
data$Cont <- factor(data$Cont, levels=c('Low', 'High'))

fit.complete <- vglm(Sat ~ Type*Infl*Cont,
                     family=multinomial(refLevel='Low'),
                     data)
fit <- vglm(Sat ~ Type + Infl + Cont,
            family=multinomial(refLevel='Low'),
            data)
#anova(fit1, fit2, test='LRT', type='I')
lrtest(fit.complete, fit) # pvalue > 0.05, no hay evidencia para descartar el reducido
c(AIC(fit.complete), AIC(fit))
c(BIC(fit.complete), BIC(fit))
```

```{r}
#iii)

fit.p <- vglm(Sat ~ Type + Infl + Cont,
              family=cumulative(parallel=T),
              data)
fit.nop <- vglm(Sat ~ Type + Infl + Cont,
                family=cumulative(parallel=F),
                data)
lrtest(fit.p, fit.nop) # pvalue > 0.05, no hay evidencia en contra de descartar el completo,
                       # es decir podemos quedarnos con el supuesto de probas proporcionales.
c(AIC(fit.nop), AIC(fit.p))
c(BIC(fit.nop), BIC(fit.p))
```

```{r}
#iv)
c(AIC(fit.p), AIC(fit))
c(BIC(fit.p), BIC(fit))

library(dplyr)
combinations <- unique(data[,3:5]) %>% arrange(Infl, Cont, Type)
odds <- predict(fit.p, combinations, type='response')
odds
combinations
infl.low <- odds[1:8,]
infl.med <- odds[9:16,]
infl.high <- odds[17:24,]
comb.tags <- c('To-L', 'Ap-L', 'At-L', 'Te-L',
               'To-H', 'Ap-H', 'At-H', 'Te-H')
row.names(infl.low) <- comb.tags
row.names(infl.med) <- comb.tags
row.names(infl.high)<- comb.tags

colors <- c('#000000', '#55415f', '#646964', '#d77355',
            '#508cd7', '#64b964', '#e6c86e', '#dcf5ff')
barplot(infl.low, beside = T, main = 'Inflence = Low', xlab = "Respuesta",
        ylab = 'Probabilidades', las = 1, col = colors, ylim = c(0,.7))
legend('topright', legend = rownames(infl.low),
       bty = 'n', fill = colors)
barplot(infl.med, beside = T, main = 'Inflence = Medium', xlab = "Respuesta",
        ylab = 'Probabilidades', las = 1, col = colors, ylim = c(0,.7))
legend('top', legend = rownames(infl.med),
       bty = 'n', fill = colors)
barplot(infl.high, beside = T, main = 'Inflence = High', xlab = "Respuesta",
        ylab = 'Probabilidades', las = 1, col = colors, ylim = c(0,.7))
legend('topleft', legend = rownames(infl.high),
       bty = 'n', fill = colors)
```




